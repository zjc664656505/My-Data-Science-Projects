{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Data Science Project 2: Exploring Hacker News Posts\n",
    "\n",
    "1. In this project, we'll work with a data set of submissions to popular technology site Hacker News.\n",
    "\n",
    "2. Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "3. Description of the dataset columns:\n",
    "    1. id: The unique identifier from Hacker News for the post\n",
    "    2. title: The title of the post\n",
    "    3. url: The URL that the posts links to, if it the post has a URL\n",
    "    4. num_points: The number of points the post acquired, calculated as   the total number of upvotes minus the total number of downvotes\n",
    "    5. num_comments: The number of comments that were made on the post\n",
    "    6. author: The username of the person who submitted the post\n",
    "    7. created_at: The date and time at which the post was submitted\n",
    "    \n",
    "4. In this project, we are particularly interested in the posts whose titles begin with either *Ask HN* or *Show HN*. \n",
    "    1. Users submit Ask HN posts to ask the Hacker News community a specific question.\n",
    "    2. Show HN posts to show the Hacker News community a project, product, or just generally something interesting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Firstly, in this project, we are going to read the dataset: hacker_news.csv file as a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "open_file = open('hacker_news.csv')\n",
    "reading = reader(open_file)\n",
    "hn = list(reading)\n",
    "\n",
    "#First five rows in this dataset\n",
    "print(hn[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hacker News headers: \n",
      " ['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "First five rows: \n",
      " [['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "#Extract the dataset header\n",
    "headers = hn[0]\n",
    "print('Hacker News headers: \\n',headers)\n",
    "\n",
    "#Remove the headers from the dataset and show it\n",
    "hn = hn[1:]\n",
    "print('First five rows: \\n', hn[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after creating and visualizing our dataset, we want to find the asking_question post, and showing post in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASK Posts numbers are:  1744\n",
      "SHOW Posts numbers are:  1162\n",
      "Other type of posts numbers are:  17194\n"
     ]
    }
   ],
   "source": [
    "#First, we create 3 empty dataset for using later\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1].lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "#After appending all corresponding types of rows, we are going to show the corresponding number of posts\n",
    "print('ASK Posts numbers are: ', len(ask_posts))\n",
    "print('SHOW Posts numbers are: ',len(show_posts))\n",
    "print('Other type of posts numbers are: ', len(other_posts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of ask comments is:  14.038417431192661\n",
      "The average number of show comments is:  10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print('The average number of ask comments is: ', avg_ask_comments)\n",
    "\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print('The average number of show comments is: ', avg_show_comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the result above, the ask post, on average, receives more posts than the show post. Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n",
    "\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 447,\n",
       " '01': 683,\n",
       " '02': 1381,\n",
       " '03': 421,\n",
       " '04': 337,\n",
       " '05': 464,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '08': 492,\n",
       " '09': 251,\n",
       " '10': 793,\n",
       " '11': 641,\n",
       " '12': 687,\n",
       " '13': 1253,\n",
       " '14': 1416,\n",
       " '15': 4477,\n",
       " '16': 1814,\n",
       " '17': 1146,\n",
       " '18': 1439,\n",
       " '19': 1188,\n",
       " '20': 1722,\n",
       " '21': 1745,\n",
       " '22': 479,\n",
       " '23': 543}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    date = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append([date, num_comments])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for row in result_list:\n",
    "    time = row[0]\n",
    "    comment = row[1]\n",
    "    hour = dt.datetime.strptime(time, date_format).strftime('%H')\n",
    "    \n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comment\n",
    "    else:\n",
    "        counts_by_hour[hour] +=1\n",
    "        comments_by_hour[hour] += comment \n",
    "\n",
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. counts_by_hour: contains the number of ask posts created during each hour of the day.\n",
    "\n",
    "2. comments_by_hour: contains the corresponding number of comments ask posts created at each hour received.\n",
    "\n",
    "Next, we'll use these two dictionaries to calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['02', 23.810344827586206],\n",
       " ['06', 9.022727272727273],\n",
       " ['17', 11.46],\n",
       " ['19', 10.8],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['01', 11.383333333333333],\n",
       " ['00', 8.127272727272727],\n",
       " ['13', 14.741176470588234],\n",
       " ['12', 9.41095890410959],\n",
       " ['15', 38.5948275862069],\n",
       " ['08', 10.25],\n",
       " ['14', 13.233644859813085],\n",
       " ['09', 5.5777777777777775],\n",
       " ['05', 10.08695652173913],\n",
       " ['22', 6.746478873239437],\n",
       " ['04', 7.170212765957447],\n",
       " ['10', 13.440677966101696],\n",
       " ['16', 16.796296296296298],\n",
       " ['07', 7.852941176470588],\n",
       " ['23', 7.985294117647059],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hr in comments_by_hour:\n",
    "    avg_by_hour.append([hr, comments_by_hour[hr] / counts_by_hour[hr]])\n",
    "\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we calculated the average number of comments for posts created during each hour of the day, and stored the results in a list of lists named avg_by_hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.810344827586206, '02'], [9.022727272727273, '06'], [11.46, '17'], [10.8, '19'], [13.20183486238532, '18'], [7.796296296296297, '03'], [16.009174311926607, '21'], [21.525, '20'], [11.383333333333333, '01'], [8.127272727272727, '00'], [14.741176470588234, '13'], [9.41095890410959, '12'], [38.5948275862069, '15'], [10.25, '08'], [13.233644859813085, '14'], [5.5777777777777775, '09'], [10.08695652173913, '05'], [6.746478873239437, '22'], [7.170212765957447, '04'], [13.440677966101696, '10'], [16.796296296296298, '16'], [7.852941176470588, '07'], [7.985294117647059, '23'], [11.051724137931034, '11']]\n",
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "\n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "template = '{0}: {1:.2f} average comments per post'\n",
    "\n",
    "for avg, hr in sorted_swap[:5]:\n",
    "    print(template.format(dt.datetime.strptime(hr, '%H').strftime('%H:%M'), \n",
    "                         avg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the result, I should create post during "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
